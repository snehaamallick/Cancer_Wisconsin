{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_is_chief': True, '_keep_checkpoint_max': 5, '_master': '', '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_task_id': 0, '_environment': 'local', '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000000BCB9940>, '_num_ps_replicas': 0, '_task_type': None, '_save_checkpoints_steps': None}\n",
      "WARNING:tensorflow:From <ipython-input-2-827749a38b5e>:54: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-2-827749a38b5e>:54: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana_ver35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:247: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ana_ver35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into /tmp/cancer_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.000299486, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 207.019\n",
      "INFO:tensorflow:loss = 0.000295896, step = 12101\n",
      "INFO:tensorflow:global_step/sec: 208.312\n",
      "INFO:tensorflow:loss = 0.000290633, step = 12201\n",
      "INFO:tensorflow:global_step/sec: 221.707\n",
      "INFO:tensorflow:loss = 0.000286842, step = 12301\n",
      "INFO:tensorflow:global_step/sec: 218.319\n",
      "INFO:tensorflow:loss = 0.00028279, step = 12401\n",
      "INFO:tensorflow:global_step/sec: 264.524\n",
      "INFO:tensorflow:loss = 0.000278441, step = 12501\n",
      "INFO:tensorflow:global_step/sec: 261.754\n",
      "INFO:tensorflow:loss = 0.000274887, step = 12601\n",
      "INFO:tensorflow:global_step/sec: 301.175\n",
      "INFO:tensorflow:loss = 0.000271209, step = 12701\n",
      "INFO:tensorflow:global_step/sec: 290.669\n",
      "INFO:tensorflow:loss = 0.00026698, step = 12801\n",
      "INFO:tensorflow:global_step/sec: 303\n",
      "INFO:tensorflow:loss = 0.000263522, step = 12901\n",
      "INFO:tensorflow:global_step/sec: 265.931\n",
      "INFO:tensorflow:loss = 0.00025982, step = 13001\n",
      "INFO:tensorflow:global_step/sec: 285.686\n",
      "INFO:tensorflow:loss = 0.000255851, step = 13101\n",
      "INFO:tensorflow:global_step/sec: 296.706\n",
      "INFO:tensorflow:loss = 0.000252555, step = 13201\n",
      "INFO:tensorflow:global_step/sec: 298.478\n",
      "INFO:tensorflow:loss = 0.000250101, step = 13301\n",
      "INFO:tensorflow:global_step/sec: 262.441\n",
      "INFO:tensorflow:loss = 0.000246563, step = 13401\n",
      "INFO:tensorflow:global_step/sec: 256.385\n",
      "INFO:tensorflow:loss = 0.00024295, step = 13501\n",
      "INFO:tensorflow:global_step/sec: 218.319\n",
      "INFO:tensorflow:loss = 0.000239977, step = 13601\n",
      "INFO:tensorflow:global_step/sec: 236.383\n",
      "INFO:tensorflow:loss = 0.000236713, step = 13701\n",
      "INFO:tensorflow:global_step/sec: 292.368\n",
      "INFO:tensorflow:loss = 0.000233846, step = 13801\n",
      "INFO:tensorflow:global_step/sec: 199.98\n",
      "INFO:tensorflow:loss = 0.000230949, step = 13901\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/cancer_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000228583.\n",
      "WARNING:tensorflow:From <ipython-input-2-827749a38b5e>:58: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-2-827749a38b5e>:58: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\ana_ver35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-30-10:02:58\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-30-10:02:59\n",
      "INFO:tensorflow:Saving dict for global step 14000: accuracy = 1.0, accuracy/baseline_label_mean = 0.5, accuracy/threshold_0.500000_mean = 1.0, auc = 1.0, global_step = 14000, labels/actual_label_mean = 0.5, labels/prediction_mean = 0.5, loss = 6.41065e-10, precision/positive_threshold_0.500000_mean = 1.0, recall/positive_threshold_0.500000_mean = 1.0\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 1.000000\n",
      "New Samples, Class Predictions:    [1, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preparing the data:\n",
    "data_file_name = 'breast-cancer-wisconsin.data.txt'\n",
    "\n",
    "# Preparing the data:\n",
    "#data_file_name = 'breast-cancer-wisconsin.data'\n",
    "\n",
    "first_line = \"id,clump_thickness,unif_cell_size,unif_cell_shape,marg_adhesion,single_epith_cell_size,bare_nuclei,bland_chrom,norm_nucleoli,mitoses,class\"\n",
    "with open(data_file_name, \"r+\") as f:\n",
    "  content = f.read()\n",
    "  f.seek(0, 0)\n",
    "  f.write(first_line.rstrip('\\r\\n') + '\\n' + content)\n",
    "\n",
    "df = pd.read_csv(data_file_name)\n",
    "\n",
    "df.replace('?', np.nan, inplace = True)\n",
    "df.dropna(inplace=True)\n",
    "df.drop(['id'], axis = 1, inplace = True)\n",
    "\n",
    "df['class'].replace('2',0, inplace = True)\n",
    "df['class'].replace('4',1, inplace = True)\n",
    "\n",
    "df.to_csv(\"combined_data.csv\", index = False)\n",
    "\n",
    "# Data sets\n",
    "CANCER_TRAINING = \"cancer_training.csv\"\n",
    "CANCER_TEST = \"cancer_test.csv\"\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(filename=CANCER_TRAINING,\n",
    "                                                       target_dtype=np.int,\n",
    "                                                       features_dtype=np.float32,\n",
    "                                                       target_column=-1)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(filename=CANCER_TEST,\n",
    "                                                   target_dtype=np.int,\n",
    "                                                   features_dtype=np.float32,\n",
    "                                                   target_column=-1)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=2)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=2,\n",
    "                                            model_dir=\"/tmp/cancer_model\")\n",
    "\n",
    "# Fit model.\n",
    "classifier.fit(x=training_set.data, \n",
    "               y=training_set.target, \n",
    "               steps=2000)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(x=test_set.data,\n",
    "                                     y=test_set.target)[\"accuracy\"]\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    "\n",
    "# Classify two new cancer tumor samples.\n",
    "def new_samples():\n",
    "  return np.array([[5, 10, 8, 4, 7, 4, 8, 11, 2],\n",
    "                   [5, 1, 1, 1, 1, 1, 1, 1, 2],\n",
    "                   [3, 1, 2, 1, 2, 10, 3, 1,5]\n",
    "                  ], dtype=np.float32)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=new_samples))\n",
    "\n",
    "print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    ".format(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
